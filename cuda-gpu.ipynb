{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:38.364426Z","iopub.execute_input":"2025-03-07T07:02:38.364765Z","iopub.status.idle":"2025-03-07T07:02:38.368989Z","shell.execute_reply.started":"2025-03-07T07:02:38.364742Z","shell.execute_reply":"2025-03-07T07:02:38.368160Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!python --version\n!nvcc --version\n!pip install nvcc4jupyter\n%load_ext nvcc4jupyter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:38.383152Z","iopub.execute_input":"2025-03-07T07:02:38.383352Z","iopub.status.idle":"2025-03-07T07:02:39.843121Z","shell.execute_reply.started":"2025-03-07T07:02:38.383336Z","shell.execute_reply":"2025-03-07T07:02:39.839685Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.12\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Tue_Aug_15_22:02:13_PDT_2023\nCuda compilation tools, release 12.2, V12.2.140\nBuild cuda_12.2.r12.2/compiler.33191640_0\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-fe9ebe2c09cf>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvcc --version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install nvcc4jupyter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nvcc4jupyter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n","\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nvcc4jupyter'"],"ename":"ModuleNotFoundError","evalue":"No module named 'nvcc4jupyter'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.843645Z","iopub.status.idle":"2025-03-07T07:02:39.843903Z","shell.execute_reply":"2025-03-07T07:02:39.843787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!g++ -v","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.844551Z","iopub.status.idle":"2025-03-07T07:02:39.844859Z","shell.execute_reply":"2025-03-07T07:02:39.844740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile cpphw.hpp\n\n#include <iostream>\n\nvoid printHelloWorld()\n\n{\n\nstd::cout << \"HelloWorld\\nHelloWorld\";\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.845602Z","iopub.status.idle":"2025-03-07T07:02:39.845982Z","shell.execute_reply":"2025-03-07T07:02:39.845826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile cpphw.cpp\n\n#include \"cpphw.hpp\"\n\nint main()\n\n{\n\nprintHelloWorld();\n\nreturn 0;\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.846868Z","iopub.status.idle":"2025-03-07T07:02:39.847226Z","shell.execute_reply":"2025-03-07T07:02:39.847071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.847899Z","iopub.status.idle":"2025-03-07T07:02:39.848256Z","shell.execute_reply":"2025-03-07T07:02:39.848096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\ng++ cpphw.cpp -std=c++11 -o hw.out\n./hw.out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.849021Z","iopub.status.idle":"2025-03-07T07:02:39.849362Z","shell.execute_reply":"2025-03-07T07:02:39.849216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day 1 (16 Feb, 2025)","metadata":{}},{"cell_type":"code","source":"%%writefile vect_add_cpu.cpp\n// Sequential Vector Addition in CPP\n\n#include <iostream>\n#include <vector>\n#include <ctime>\nusing namespace std;\n\nint main(){\n    clock_t start = clock();\n    int n = 200000000;\n    vector<int> A(n), B(n), C(n);\n    for (int i=0; i<n; i++){\n        A[i] = i+1;\n        B[i] = (i+1)*2;\n    }\n\n    for (int i=0;i<n; i++){\n        C[i] = A[i] + B[i];\n\n    }\n\n    clock_t end = clock();\n\n    double duration = static_cast<double>(end - start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"Time taken: \" << duration * 1000 << \" milliseconds\" << std::endl; // Convert to milliseconds\n\n    for (int i=0;i <20; i++){\n        cout << C[i] << \" \";\n    }\n    return 0;\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.849945Z","iopub.status.idle":"2025-03-07T07:02:39.850268Z","shell.execute_reply":"2025-03-07T07:02:39.850110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\ng++ vect_add_cpu.cpp -std=c++11 -o cpu.out\n./cpu.out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.851260Z","iopub.status.idle":"2025-03-07T07:02:39.851537Z","shell.execute_reply":"2025-03-07T07:02:39.851420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile vect_add_gpu.cu\n// vector addition on gpu\n\n#include <iostream>\n#include <vector>\n#include <ctime>\n#include <cuda_runtime.h>\n\nusing namespace std;\n\n__global__ void vector_addition(int *A, int *B, int *C, int n){\n    // std::cout << \"blockIdx.x = \" << blockIdx.x << endl ;\n    // std::cout << \"blockDim.x = \" << blockDim.x << endl ;\n    // std::cout << \"threadIdx.x = \" << threadIdx.x << endl ;\n\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i<n){\n        C[i] = A[i] + B[i];\n    }\n    \n};\n\nint main(){\n    int n = 200000000;\n    vector<int> A(n), B(n), C(n);\n    for (int i=0; i<n; i++){\n        A[i] = i+1;\n        B[i] = (i+1)*2;\n    }\n\n    clock_t start = clock();\n    int *d_A, *d_B, *d_C;\n    cudaMalloc((void **)&d_A, n*sizeof(int));\n    cudaMalloc((void **)&d_B, n*sizeof(int));\n    cudaMalloc((void **)&d_C, n*sizeof(int));\n\n    cudaMemcpy(d_A, A.data(), n*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B.data(), n*sizeof(int), cudaMemcpyHostToDevice);\n\n    int blockSize = 2;\n    int gridSize = n+blockSize - 1;\n    \n    vector_addition <<<gridSize, blockSize>>>(d_A, d_B, d_C, n);\n    cudaMemcpy(C.data(), d_C, n*sizeof(int), cudaMemcpyDeviceToHost);\n\n    clock_t end = clock();\n\n    double duration = static_cast<double>(end - start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"Time taken: \" << duration * 1000 << \" milliseconds\" << std::endl; // Convert to milliseconds\n\n    for (int i=0;i <20; i++){\n        cout << C[i] << \" \";\n    }\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n    \n    return 0;  \n}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.852562Z","iopub.status.idle":"2025-03-07T07:02:39.852868Z","shell.execute_reply":"2025-03-07T07:02:39.852723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc vect_add_gpu.cu -o kernel\n./kernel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.853962Z","iopub.status.idle":"2025-03-07T07:02:39.854327Z","shell.execute_reply":"2025-03-07T07:02:39.854165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Notes:\n* Gird Dimension: gridDim.x, gridDim.y, gridDim.z is the number of blocks in each direction of Grid.\n* Block Dimension: blockDim.x, blockDim.y, blockDim.z, is the number of threads in each direction of block.\n* Block Index: blockIdx.x[y,z], index of the block within the grid\n* Thread Index: threadIdx.x[y,z], index of thread within a block\n  \nthreadId =\n\n            blockDim.x\\*blockIdx.x + blockDim.x\\*threadIdx.y + threadIdx.x (simple 2D within a block) +\n              \n            gridDim.x\\*blockDim.y\\*blockIdx.y (blocks of threads in previous row) \n\n\n**Steps:**\n1. Define the function to run on GPU.\n2. Declare variables on CPU and allocate necessary memory on GPU\n3. Copy the data from CPU to GPU on the allocated locations.\n4. Call the kernel\n5. Save the copy of the task result on the CPU.\n6. free the memory on GPU\n","metadata":{}},{"cell_type":"markdown","source":"# Day 2 (17 Feb, 2025)","metadata":{"execution":{"iopub.status.busy":"2025-02-17T17:26:03.433641Z","iopub.execute_input":"2025-02-17T17:26:03.434097Z","iopub.status.idle":"2025-02-17T17:26:03.439567Z","shell.execute_reply.started":"2025-02-17T17:26:03.434055Z","shell.execute_reply":"2025-02-17T17:26:03.437465Z"}}},{"cell_type":"code","source":"%%writefile vect_2D_add_gpu.cu\n// vector addition on gpu\n\n#include <iostream>\n#include <vector>\n#include <ctime>\n#include <cuda_runtime.h>\n\nusing namespace std;\n\n__global__ void vector_addition(int *A, int *B, int *C, int rows, int cols){\n    // std::cout << \"blockIdx.x = \" << blockIdx.x << endl ;\n    // std::cout << \"blockDim.x = \" << blockDim.x << endl ;\n    // std::cout << \"threadIdx.x = \" << threadIdx.x << endl ;\n\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row < rows && col < cols){\n        int index = row*cols + col;\n       // std::cout << index << endl;\n        C[index] = A[index] + B[index];\n    }\n    \n};\n\nvoid print_vector(vector<vector <int>> matrix){\n  // vector<vector<int>> matrix(3);\n    for (vector vec: matrix){\n      for (int val : vec){\n        cout << val << \" \";\n      }\n      cout << endl;\n    }\n}\n\n// Helper function to check for CUDA errors\nvoid checkCudaError(cudaError_t error) {\n    if (error != cudaSuccess) {\n        std::cerr << \"CUDA Error: \" << cudaGetErrorString(error) << std::endl;\n        exit(EXIT_FAILURE);\n    }\n}\n\nint main(){\n    \n    int rows = 30000;\n    int cols = 30000;\n    int n = rows*cols;\n    vector<int> h_A(n), h_B(n), h_C(n);\n    for (int i = 0; i < rows; ++i) {\n        for (int j = 0; j < cols; ++j) {\n            h_A[i * cols + j] = 2; // Example initialization for A\n            h_B[i * cols + j] = -1;\n                }\n    }\n\n    clock_t start_cpu = clock();\n    for (int i = 0; i < rows; ++i) {\n        for (int j = 0; j < cols; ++j) {\n            h_C[i * cols + j] = h_A[i * cols + j] + h_B[i * cols + j];\n                }\n    }\n    clock_t end_cpu = clock();\n    double duration_cpu = static_cast<double>(end_cpu - start_cpu) / CLOCKS_PER_SEC; // Time in seconds\n    std::cout << \"CPU Time taken: \" << duration_cpu * 1000 << \" milliseconds\" << std::endl; \n\n    clock_t start = clock();\n    int *d_A, *d_B, *d_C;\n    checkCudaError(cudaMalloc((void **)&d_A, n*sizeof(int)));\n    checkCudaError(cudaMalloc((void **)&d_B, n*sizeof(int)));\n    checkCudaError(cudaMalloc((void **)&d_C, n*sizeof(int)));\n\n    checkCudaError(cudaMemcpy(d_A, h_A.data(), n*sizeof(int), cudaMemcpyHostToDevice));\n    checkCudaError(cudaMemcpy(d_B, h_B.data(), n*sizeof(int), cudaMemcpyHostToDevice));\n\n    // dim3 blockSize(rows, cols); // Block dimension (threads per block in x and y) - adjust based on matrix size and GPU capabilities\n    // dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);\n\n    dim3 blockSize(16, 16); // Example block size\n    blockSize.x = min(blockSize.x, cols); // Clamp block size to cols\n    blockSize.y = min(blockSize.y, rows); // Clamp block size to rows\n    dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);\n    \n    vector_addition <<<gridSize, blockSize>>>(d_A, d_B, d_C, rows, cols);\n    checkCudaError(cudaGetLastError());\n    clock_t d2h_start = clock();\n    checkCudaError(cudaMemcpy(h_C.data(), d_C, n*sizeof(int), cudaMemcpyDeviceToHost));\n    clock_t d2h_end = clock();\n    double d2h_duration = static_cast<double>(d2h_end - d2h_start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"MemCpy D2H Time taken: \" << d2h_duration * 1000 << \" milliseconds\" << std::endl; \n\n    clock_t end = clock();\n\n    double duration_cuda = static_cast<double>(end - start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"CUDA Time taken: \" << duration_cuda * 1000 << \" milliseconds\" << std::endl; \n    // Convert to milliseconds\n\n    cout << \"CUDA Matrix Addition (2D):\" << endl;\n    \n    for (int i = 0; i < 10; ++i) {\n        for (int j = 0; j < 10; ++j) {\n            cout << h_C[i * cols + j] << \" \";\n        }\n        cout << endl;\n    }\n    checkCudaError(cudaFree(d_A));\n    checkCudaError(cudaFree(d_B));\n    checkCudaError(cudaFree(d_C));\n    checkCudaError(cudaDeviceSynchronize());\n    \n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.855153Z","iopub.status.idle":"2025-03-07T07:02:39.855503Z","shell.execute_reply":"2025-03-07T07:02:39.855350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc vect_2D_add_gpu.cu -o vect_2d\n./vect_2d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.856442Z","iopub.status.idle":"2025-03-07T07:02:39.856833Z","shell.execute_reply":"2025-03-07T07:02:39.856647Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day 3 (18 Feb, 2025)","metadata":{}},{"cell_type":"markdown","source":"Chapter 3 Notes:\n* dim3 dimGrid(32,1,1), dim dimBlock(128,1,1) or dim3 dog(32,1,1), dim3 cat(128,1,1)\n* vec_add <<<dimGrid or dog, dimBlock or cat>>> // we can use both with dim3 type, it is vector of int type with 3 elements, x, y, z.\n* \"For convenience, CUDA provides a special shortcut for calling a kernel with one-dimensional (1D) grids and blocks. Instead of using dim3 variables, one can use arithmetic expressions to specify the configuration of 1D grids and blocks. In this case, the CUDA compiler simply takes the arithmetic expression as the x dimensions and assumes that the y and z dimensions are 1.\" Page 49\n* \"the gridDim and blockDim are built-in variables in a kernel and always reflect the dimensions of the grid and the blocks, respectively.\"\n* the allowed values of gridDim.x range from 1 to 231 2 1,1 and those of gridDim.y and gridDim.z range from 1 to 216 2 1 (65,535).\n* The total size of a block in current CUDA systems is limited to 1024 threads. These threads can be distributed across the three dimensions in any way as long as the total number of threads does not exceed 1024.\n* We need to know the no of cols at the compile time to accept dynamically allocated  arrays, but we do not have this info, as a result we flattne the dynamically allocated 2D arrays into an equivalent 1D arrays.\n* The linearized access to a 3D array P will be in the form of P[plane * m * n +row * m + col].","metadata":{}},{"cell_type":"code","source":"%%writefile matrix_mul.cu\n\n#include <iostream>\n#include <vector>\n#include <ctime>\n#include <cuda_runtime.h>\n\nusing namespace std;\n\n__global__ void mat_mul(int *P_A, int *P_B,int *P_C, int Width){\n    int row = blockDim.y*blockIdx.y + threadIdx.y;\n    int col = blockDim.x*blockIdx.x + threadIdx.x;\n\n    if (row < Width && col < Width){\n        for (int k=0; k<Width; k++){\n            P_C[row*Width+col] += P_A[row*Width+k] * P_B[k*Width+col];\n        }\n    }\n}\n\nvoid checkCudaError(cudaError_t error) {\n    if (error != cudaSuccess) {\n        std::cerr << \"CUDA Error: \" << cudaGetErrorString(error) << std::endl;\n        exit(EXIT_FAILURE);\n    }\n}\nint main(){\n    int rows = 30000;\n    int cols = 30000;\n    int n = rows*cols;\n    vector<int> h_A(n), h_B(n), h_C(n);\n    for (int i = 0; i < rows; ++i) {\n        for (int j = 0; j < cols; ++j) {\n            h_A[i * cols + j] = 1; // Example initialization for A\n            h_B[i * cols + j] = 2;\n                }\n    }\n    clock_t start = clock();\n    int *d_A, *d_B, *d_C;\n    checkCudaError(cudaMalloc((void **)&d_A, n*sizeof(int)));\n    checkCudaError(cudaMalloc((void **)&d_B, n*sizeof(int)));\n    checkCudaError(cudaMalloc((void **)&d_C, n*sizeof(int)));\n\n    checkCudaError(cudaMemcpy(d_A, h_A.data(), n*sizeof(int), cudaMemcpyHostToDevice));\n    checkCudaError(cudaMemcpy(d_B, h_B.data(), n*sizeof(int), cudaMemcpyHostToDevice));\n\n    int width = rows;\n    dim3 blockSize(32, 32); // Example block size\n    blockSize.x = min(blockSize.x, cols); // Clamp block size to cols\n    blockSize.y = min(blockSize.y, rows); // Clamp block size to rows\n    dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);\n\n    clock_t gpu_start = clock();\n    mat_mul <<<gridSize, blockSize>>>(d_A, d_B, d_C, width);\n    clock_t gpu_end = clock();\n    double gpu_duration = static_cast<double>(gpu_end - gpu_start) / CLOCKS_PER_SEC; // Time in seconds\n    std::cout << \"GPU Time taken: \" << gpu_duration * 1000 << \" milliseconds\" << std::endl; \n    \n    clock_t d2h_start = clock();\n    checkCudaError(cudaMemcpy(h_C.data(), d_C, n*sizeof(int), cudaMemcpyDeviceToHost));\n    clock_t d2h_end = clock();\n    double d2h_duration = static_cast<double>(d2h_end - d2h_start) / CLOCKS_PER_SEC; // Time in seconds\n    std::cout << \"MemCpy D2H Time taken: \" << d2h_duration * 1000 << \" milliseconds\" << std::endl; \n\n    checkCudaError(cudaGetLastError());\n    cout << \"CUDA Matrix Mul (2D):\" << endl;\n    \n    for (int i = 0; i < 10; ++i) {\n        for (int j = 0; j < 10; ++j) {\n            cout << h_C[i * cols + j] << \" \";\n        }\n        cout << endl;\n    }\n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.857997Z","iopub.status.idle":"2025-03-07T07:02:39.858351Z","shell.execute_reply":"2025-03-07T07:02:39.858197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc matrix_mul.cu -o mul\n./mul","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.859114Z","iopub.status.idle":"2025-03-07T07:02:39.859502Z","shell.execute_reply":"2025-03-07T07:02:39.859333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.860396Z","iopub.status.idle":"2025-03-07T07:02:39.860763Z","shell.execute_reply":"2025-03-07T07:02:39.860598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day 4 (19 Feb, 2025)","metadata":{}},{"cell_type":"markdown","source":"### Notes\n#### Shared Memory\n* On-chip memory that is physically located close to the GPU cores, unlike global memory (DRAM) which is off-chip.\n* Low Latency, High bandwith, Shared within a block, Limited Size.","metadata":{}},{"cell_type":"code","source":"!python --version\n!nvcc --version\n!pip install nvcc4jupyter\n%load_ext nvcc4jupyter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.861483Z","iopub.status.idle":"2025-03-07T07:02:39.861861Z","shell.execute_reply":"2025-03-07T07:02:39.861679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile red.cu\n#include <iostream>\n#include <vector>\n#include <cuda_runtime.h>\n#include <ctime>\n\nusing namespace std;\nvoid checkCudaError(cudaError_t error){\n    if (error != cudaSuccess){\n        cerr << \"Cuda Error: \" << cudaGetErrorString(error) << endl;\n        exit(EXIT_FAILURE);\n    }\n}\n\n__global__ void reduction_tree(float *input, float*output, int block_size){\n\n    __shared__ float shared_data[256];\n\n    int thread_id = threadIdx.x;\n    int block_id = blockIdx.x;\n    shared_data[thread_id] = input[block_id*block_size + thread_id];\n    __syncthreads();\n\n    for (int stride=block_size / 2; stride > 0; stride/=2){\n        if (thread_id < stride){\n            shared_data[thread_id] += shared_data[thread_id + stride];\n        }\n        __syncthreads();\n    }\n    if (thread_id == 0){\n        output[block_id] = shared_data[0];\n    }\n}\n\nint main(){\n    int array_size = 1024*1024*4*4;\n    int block_size = 32;\n\n    vector<float> h_input(array_size);\n    vector<float> h_output((array_size + block_size - 1) / block_size, 0.0f);\n\n    for (int i=0; i < array_size; i++){\n        // h_input[i] = (float) (i%10+1);\n        h_input[i] = 1;\n    }\n    \n    float *d_input, *d_output;\n    checkCudaError(cudaMalloc((void**)&d_input, array_size * sizeof(float)));\n    checkCudaError(cudaMalloc((void**)&d_output, h_output.size() * sizeof(float)));\n\n    checkCudaError(cudaMemcpy(d_input, h_input.data(), array_size * sizeof(float), cudaMemcpyHostToDevice));\n\n    dim3 blockDim(block_size);\n    dim3 gridDim((array_size+block_size-1)/block_size);\n\n    clock_t cpu_start = clock();\n    int array_sum = 0;\n    for (int i=0; i < array_size; i++){\n        array_sum += h_input[i];\n    }\n    clock_t cpu_end = clock();\n    double cpu_duration = static_cast<double>(cpu_end - cpu_start) / CLOCKS_PER_SEC; // Time in seconds\n    std::cout << \"CPU Time taken: \" << cpu_duration * 1000 << \" milliseconds\" << std::endl; \n\n    clock_t gpu_start = clock();\n    reduction_tree <<<gridDim, blockDim>>>(d_input, d_output, block_size);\n    clock_t gpu_end = clock();\n    double gpu_duration = static_cast<double>(gpu_end - gpu_start) / CLOCKS_PER_SEC; // Time in seconds\n    std::cout << \"GPU Time taken: \" << gpu_duration * 1000 << \" milliseconds\" << std::endl; \n    checkCudaError(cudaMemcpy(h_output.data(), d_output, h_output.size() * sizeof(float), cudaMemcpyDeviceToHost));\n\n    int gpu_sum = 0;\n    for (int i = 0; i < h_output.size(); i++){\n        gpu_sum += h_output[i];\n    }\n    cout << \"shared memory array size: \" << 256 << endl;\n    cout << \"gpu sum \" << gpu_sum<< endl;\n    cout << \"cpu sum \" << array_sum << endl;\n    checkCudaError(cudaFree(d_input));\n    checkCudaError(cudaFree(d_output));\n    \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.862837Z","iopub.status.idle":"2025-03-07T07:02:39.863195Z","shell.execute_reply":"2025-03-07T07:02:39.863041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc red.cu -o red\n./red","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.864150Z","iopub.status.idle":"2025-03-07T07:02:39.864585Z","shell.execute_reply":"2025-03-07T07:02:39.864356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"{32: 0.225 milliseconds,\n 64: 0.219,\n 128: 0.182,\n 256: 0.212,\n 512:\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.865438Z","iopub.status.idle":"2025-03-07T07:02:39.865843Z","shell.execute_reply":"2025-03-07T07:02:39.865667Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day 5 (Feb 20, 2025)\n* with blockSize > 256 when shared memory is 256, we are likely writing out of bounds of the sharedData array, leading to undefined behavior and potential errors.\n* dynamic shared memory, you declare it as extern __shared__ float sharedData[]; in the kernel and then specify the size in bytes when you launch the kernel using the sharedMemConfig parameter of the kernel launch <<<>>>.","metadata":{}},{"cell_type":"code","source":"    for (int i=0; i < neurons; i++ ){\n        for (int j=0; j < sample; j++){\n            cout << i << j << \" \" ;\n            cout <<  neurons*i + j << endl;\n            \n            h_input[neurons*i + j] = neurons*i + j;\n        }\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.866668Z","iopub.status.idle":"2025-03-07T07:02:39.867011Z","shell.execute_reply":"2025-03-07T07:02:39.866856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile navie_layer_norm.cpp\n#include <iostream>\n#include <vector>\n#include <ctime>\n#include <stdio.h>\n#include <cmath>\n\nusing namespace std;\nvoid print_matrix(vector<float> matrix, int neurons, int sample ){\n    for (int i=0; i < neurons; i++ )\n        {\n        for (int j=0; j < sample; j++)\n        {\n            cout <<  matrix[sample*i + j] << \" \";\n        }\n        cout << endl ;\n        }\n    }\nint main()\n    {\n    //ex1 - a11, a21, a31; ex2 - a12, a22, a32, mean1 = (a11 + a12)/2\n    \n    int sample = 100000;  // cols\n    int neurons = 32; // rows\n\n    int array_size = sample * neurons;\n    vector<float> h_input(array_size);\n    \n    for (int i=0; i < neurons; i++ ){\n        for (int j=0; j < sample; j++){\n            h_input[sample*i + j] = sample*i + j;\n        }\n    }\n\n    // printf(\"input matrix \\n\");\n    // print_matrix(h_input, neurons, sample);\n\n    vector<float> h_mean(sample);\n    vector<float> h_var(sample, 0);\n    vector<float> h_std(sample, 0);\n    \n    for (int i=0; i < neurons; i++ ){\n        float col_sum = 0;\n        for (int j=0; j < sample; j++){\n            h_mean[j] += h_input[sample*i + j]; \n            }\n        }\n    for (int j=0; j < sample; j++){\n         h_mean[j] = h_mean[j]/neurons;\n        }\n//    printf(\"col mean: \\n\");\n//    for (float val: h_mean){\n//        cout << (val) << \" \";\n//    }\n//    printf(\"\\n\");\n\n    for (int i=0; i < neurons; i++ ){\n        for (int j=0; j < sample; j++){ \n            h_var[j] += ( h_input[sample*i + j] - h_mean[j]) * ( h_input[sample*i + j] - h_mean[j]); \n            }\n        }\n\n    for (int j=0; j < sample; j++){\n         h_std[j] = sqrt(h_var[j]/neurons);\n        }\n\n//   printf(\"col diff sqr sum: \\n\");\n//   for (float val: h_var){\n//       cout << (val) << \" \";\n//   }\n//   printf(\"\\n\");\n//\n//   printf(\"col std: \\n\");\n//   for (float val: h_std){\n//       cout << (val) << \" \";\n//   }\n//   printf(\"\\n\\nprinting output matrix \\n\\n\");\n//\n    clock_t cpu_start = clock();\n    vector<float> h_output(array_size,0);\n    for (int i=0; i < neurons; i++ ){\n        for (int j=0; j < sample; j++){\n            h_output[sample*i + j] = (h_input[sample*i + j] - h_mean[j])/(h_std[j] + 1e-7);\n            float val =  h_output[sample*i + j];\n            // cout << (val) << \" \";\n        }\n        // cout << endl;\n    }\n   \n    \n    for (int i=0; i < neurons; i++ ){\n        for (int j=0; j < sample; j++){\n            h_output[sample*i + j] = (h_input[sample*i + j] - h_mean[j])/(h_std[j] + 1e-7);\n            float val =  h_output[sample*i + j];\n            // cout << (val) << \" \";\n        }\n        // cout << endl;\n    }\n    clock_t cpu_end = clock();\n    double cpu_duration = static_cast<double>(cpu_end - cpu_start) / CLOCKS_PER_SEC; // Time in seconds\n    std::cout << \"CPU Time taken: \" << cpu_duration * 1000 << \" milliseconds\" << std::endl; \n\n    return 0;\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.867952Z","iopub.status.idle":"2025-03-07T07:02:39.868263Z","shell.execute_reply":"2025-03-07T07:02:39.868105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\ng++ navie_layer_norm.cpp -o layer\n./layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.868900Z","iopub.status.idle":"2025-03-07T07:02:39.869205Z","shell.execute_reply":"2025-03-07T07:02:39.869094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python --version\n!nvcc --version\n!pip install nvcc4jupyter\n%load_ext nvcc4jupyter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.870642Z","iopub.status.idle":"2025-03-07T07:02:39.870984Z","shell.execute_reply":"2025-03-07T07:02:39.870803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day 6 (Feb 21, 2025)","metadata":{}},{"cell_type":"code","source":"%%writefile layerNorm1.cu\n#include <vector>\n#include <iostream>\n#include <ctime>\n#include <cuda_runtime.h>\n#include <cmath>\n\nusing namespace std;\n\n__global__ void layer_norm(float *data, float *mean, float *var, float *output,  int neurons, int sample){\n    int idx = blockIdx.x *  blockDim.x + threadIdx.x;\n   // std::cout << idx;\n    if (idx  <  gridDim.x * blockDim.x ){\n        mean[idx] = 0.0f;\n        var[idx] = 0.0f;\n        for (int i=0; i < neurons; i++ ){\n\n            int row_idx = idx*neurons + i;\n            mean[idx] += data[row_idx];\n            \n        }\n        mean[idx] /= neurons;\n        for (int i=0; i < neurons; i++ ){\n\n            int row_idx = idx*neurons + i;\n            var[idx] += ((data[row_idx]-mean[idx]) * (data[row_idx]-mean[idx]));\n            \n        }\n        var[idx] /= neurons;\n        for (int i=0; i < neurons; i++ ){\n\n            int row_idx = idx*neurons + i;\n            output[row_idx] = (data[row_idx] - mean[idx])/(sqrt(var[idx])+1e-7);\n            \n        }\n        }\n}\n\nint main(){\n    int sample = 10024;\n    int neurons = 10024;\n    vector<float> h_data(sample*neurons);\n    vector<float> h_out(sample*neurons);\n    vector<float> h_mean(sample);\n    vector<float> h_var(sample); \n\n    for (int i =0; i < sample; i++){\n        for (int j =0; j < neurons; j++){\n        h_data[i*neurons + j] = i*neurons + j;\n        }\n    }\n\n    cudaEvent_t start, stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n\n    float *d_data, *d_out, *d_mean, *d_var;\n    cudaMalloc((void **)&d_data, sample*neurons*sizeof(float));\n    cudaMalloc((void **)&d_out, sample*neurons*sizeof(float));\n    cudaMalloc((void **)&d_mean, sample*sizeof(float));\n    cudaMalloc((void **)&d_var, sample*sizeof(float));\n\n    cudaMemcpy(d_data, h_data.data(), sample*neurons*sizeof(float), cudaMemcpyHostToDevice );\n    cudaMemcpy(d_out, h_out.data(), sample*neurons*sizeof(float), cudaMemcpyHostToDevice );\n    cudaMemcpy(d_mean, h_mean.data(), sample*sizeof(float), cudaMemcpyHostToDevice );\n    cudaMemcpy(d_var, h_var.data(), sample*sizeof(float), cudaMemcpyHostToDevice );\n\n    dim3 blockSize(256);\n    dim3 gridSize((sample*neurons + blockSize.x - 1) / blockSize.x);  // Proper grid size calculation\n\n    float total_ms = 0;\n    for (int i = 0; i < 10; i++){\n        cudaEventRecord(start);\n        layer_norm<<<gridSize, blockSize>>>(d_data, d_mean, d_var, d_out, neurons, sample);\n        cudaDeviceSynchronize();\n        cudaEventRecord(stop);\n        cudaEventSynchronize(stop);\n        float milliseconds = 0;\n        cudaEventElapsedTime(&milliseconds, start, stop);\n        total_ms += milliseconds;\n    }\n    float averageMilliseconds = total_ms / 10;\n    std::cout << \"Average kernel execution time: \" << averageMilliseconds << \" ms\" << std::endl;\n\n    cudaMemcpy(h_mean.data(), d_mean, sample*sizeof(float), cudaMemcpyDeviceToHost );\n    cudaMemcpy(h_var.data(), d_var, sample*sizeof(float), cudaMemcpyDeviceToHost );\n    cudaMemcpy(h_out.data(), d_out, sample*neurons*sizeof(float), cudaMemcpyDeviceToHost );\n\n    cudaFree(d_out);\n    cudaFree(d_mean);\n    cudaFree(d_var);\n    cudaFree(d_data);\n    return 0;\n\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.871943Z","iopub.status.idle":"2025-03-07T07:02:39.872244Z","shell.execute_reply":"2025-03-07T07:02:39.872097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc layerNorm1.cu -o red1\n./red1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.874379Z","iopub.status.idle":"2025-03-07T07:02:39.874689Z","shell.execute_reply":"2025-03-07T07:02:39.874542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile elapsed.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\n// Simple kernel to perform vector addition\n__global__ void vectorAdd(float* a, float* b, float* c, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < n) {\n        c[i] = a[i] + b[i];\n    }\n}\n\nint main() {\n    int n = 1024 * 1024; // Example size\n    float* h_a, * h_b, * h_c; // Host arrays\n    float* d_a, * d_b, * d_c; // Device arrays\n\n    // Allocate memory on host\n    h_a = new float[n];\n    h_b = new float[n];\n    h_c = new float[n];\n\n    // Allocate memory on device\n    cudaMalloc(&d_a, n * sizeof(float));\n    cudaMalloc(&d_b, n * sizeof(float));\n    cudaMalloc(&d_c, n * sizeof(float));\n\n    // Initialize host arrays (example values)\n    for (int i = 0; i < n; i++) {\n        h_a[i] = i;\n        h_b[i] = 2 * i;\n    }\n\n    // Copy data from host to device\n    cudaMemcpy(d_a, h_a, n * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, n * sizeof(float), cudaMemcpyHostToDevice);\n\n\n    // Kernel launch configuration\n    int blockSize = 256;\n    int gridSize = (n + blockSize - 1) / blockSize;\n\n    cudaEvent_t start, stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n\n    int numRuns = 100;\n    float totalMilliseconds = 0;\n\n        // Warm-up runs\n    for (int i = 0; i < 5; ++i) {\n        vectorAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n        cudaDeviceSynchronize(); // Synchronize after warm-up runs\n    }\n\n\n    for (int i = 0; i < numRuns; ++i) {\n        cudaEventRecord(start);\n        vectorAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n        cudaEventRecord(stop);\n        cudaEventSynchronize(stop);\n        float milliseconds = 0;\n        cudaEventElapsedTime(&milliseconds, start, stop);\n        totalMilliseconds += milliseconds;\n    }\n\n    float averageMilliseconds = totalMilliseconds / numRuns;\n    std::cout << \"Average kernel execution time: \" << averageMilliseconds << \" ms\" << std::endl;\n\n    // Copy results back to host (optional, for verification)\n    //cudaMemcpy(h_c, d_c, n * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // Free memory\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n    delete[] h_a;\n    delete[] h_b;\n    delete[] h_c;\n\n    cudaEventDestroy(start);\n    cudaEventDestroy(stop);\n    cudaDeviceReset(); // Important: Release CUDA resources\n\n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.876019Z","iopub.status.idle":"2025-03-07T07:02:39.876321Z","shell.execute_reply":"2025-03-07T07:02:39.876187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc elapsed.cu -o elp\n./elp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.878574Z","iopub.status.idle":"2025-03-07T07:02:39.878954Z","shell.execute_reply":"2025-03-07T07:02:39.878779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python --version\n!nvcc --version\n!pip install nvcc4jupyter\n%load_ext nvcc4jupyter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.879921Z","iopub.status.idle":"2025-03-07T07:02:39.880200Z","shell.execute_reply":"2025-03-07T07:02:39.880092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile t.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\nconst int TILE_DIM = 32;\nconst int num_runs = 100;\n\n// Simple kernel to perform vector addition\n__global__ void matrix_copy(float* in_matrix, float* out_matrix, int n) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    int block_rows = blockDim.y;\n    int size = blockDim.x * gridDim.x; // as rows == cols\n    if (x < n && y < n)\n        for (int dim_y = 0; dim_y < gridDim.y; dim_y += block_rows){\n            out_matrix[(dim_y+ y)*size + x] = in_matrix[(dim_y+ y)*size + x];\n        }\n}\n\n__global__ void navie_transpose(float* in_matrix, float* out_matrix, int n) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    int block_rows = blockDim.y;\n    int size = blockDim.x * gridDim.x; // as rows == cols\n    if (x < n && y < n)\n        for (int dim_y = 0; dim_y < gridDim.y; dim_y += block_rows){\n            out_matrix[x*size + (dim_y + y)] = in_matrix[(dim_y + y)*size + x];\n        }\n\n}\n\n__global__ void shared_copy(float* in_matrix, float* out_matrix, int n) {\n    __shared__ float share[TILE_DIM * TILE_DIM];\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    // int block_rows = blockDim.y;\n    // int size = blockDim.x * gridDim.x; // as rows == cols\n    if (x < n && y < n)\n        share[(threadIdx.y)*blockDim.y + threadIdx.x] = in_matrix[(y)*n + x];\n        __syncthreads();\n        // for (int dim_y = 0; dim_y < gridDim.y; dim_y += block_rows)\n        {\n        out_matrix[(y)*n + x] = share[(threadIdx.x)*blockDim.x + threadIdx.y];\n        }\n\n    }\n\n__global__ void shared_coalesced_bank_conflict(float *in_matrix, float *out_matrix, int n){\n    __shared__ float tile[TILE_DIM][TILE_DIM];\n    int x = blockIdx.x*blockDim.x + threadIdx.x;\n    int y = blockIdx.y*blockDim.y + threadIdx.y;\n\n    int width = n;\n    if (x < n && y < n){\n        tile[threadIdx.y][threadIdx.x] = in_matrix[(y * width ) + threadIdx.x];\n    }\n    __syncthreads();\n    \n    x = blockIdx.y*blockDim.x + threadIdx.x;\n    y = blockIdx.x*blockDim.y + threadIdx.y;\n    if (x < n && y < n){\n        out_matrix[(y*width) + x] = tile[threadIdx.x][threadIdx.y];\n    }\n }\n\n __global__ void shared_coalesced_no_bank_conflict(float *in_matrix, float *out_matrix, int n){\n    __shared__ float tile[TILE_DIM][TILE_DIM + 1];\n    int x = blockIdx.x*blockDim.x + threadIdx.x;\n    int y = blockIdx.y*blockDim.y + threadIdx.y;\n\n    int width = n;\n    if (x < n && y < n){\n        tile[threadIdx.y][threadIdx.x] = in_matrix[(y * width ) + threadIdx.x];\n    }\n    __syncthreads();\n    \n    x = blockIdx.y*blockDim.x + threadIdx.x;\n    y = blockIdx.x*blockDim.y + threadIdx.y;\n    if (x < n && y < n){\n        out_matrix[(y*width) + x] = tile[threadIdx.x][threadIdx.y];\n    }\n }\n\nint main() {\n    int rows = 1024;\n    int cols = 1024;\n    int size = rows * cols; \n    float *c_data, *c_output; // Host arrays\n    float *d_data, *d_output; // Device arrays\n\n    // Allocate memory on host\n    c_data = new float[size];\n    c_output = new float[size];\n\n    // Allocate memory on device\n    cudaMalloc((void **)&d_data, size * sizeof(float));\n    cudaMalloc((void **)&d_output, size * sizeof(float));\n    // cudaMallocHost creates a pinned memory, avoids the overhead of pageable -> pinned memory\n    // When executed cudaMallocHost, the execution time impacted, not all the time the pinned meory is efficient\n\n    // Initialize host arrays (example values)\n    for (int row = 0; row < rows; row ++){\n        for (int col = 0; col < cols; col++){\n            c_data[row*cols + col] = row*cols + col;\n        }\n    }\n\n    // Copy data from host to device\n    cudaMemcpy(d_data, c_data, size * sizeof(float), cudaMemcpyHostToDevice);\n\n\n    // Kernel launch configuration\n    dim3 blockSize(32, 32, 1);\n    dim3 gridSize(32, 32, 1);\n\n    printf(\"%25s%25s%25s\\n\", \"Exectution\", \"Bandwidth (GB/s)\", \"GPU Time (ms)\");\n    printf(\"\\n\");\n\n    printf(\"%25s\",\"Matrix Copy\");\n\n    cudaEvent_t start1, stop1;\n    cudaEventCreate(&start1);\n    cudaEventCreate(&stop1);\n    float total_milliseconds1 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start1);\n        matrix_copy<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        //navie_transpose<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop1);\n        cudaEventSynchronize(stop1);\n        float milliseconds1 = 0;\n        cudaEventElapsedTime(&milliseconds1, start1, stop1);\n        total_milliseconds1 += milliseconds1;\n    }\n    float average_milliseconds1 = total_milliseconds1 / num_runs;\n    cudaEventDestroy(start1);\n    cudaEventDestroy(stop1);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds1, average_milliseconds1 );\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"Shared Copy\");\n\n    cudaEvent_t start2, stop2;\n    cudaEventCreate(&start2);\n    cudaEventCreate(&stop2);\n    \n    float total_milliseconds2 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start2);\n        shared_copy<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop2);\n        cudaEventSynchronize(stop2);\n        float milliseconds2 = 0;\n        cudaEventElapsedTime(&milliseconds2, start2, stop2);\n        total_milliseconds2 += milliseconds2;\n    }\n    float average_milliseconds2 = total_milliseconds2 / num_runs;\n    cudaEventDestroy(start2);\n    cudaEventDestroy(stop2);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds2, average_milliseconds2 );\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"Navie Transpose\");\n\n    cudaEvent_t start3, stop3;\n    cudaEventCreate(&start3);\n    cudaEventCreate(&stop3);\n    float total_milliseconds3 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start3);\n        navie_transpose<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop3);\n        cudaEventSynchronize(stop3);\n        float milliseconds3 = 0;\n        cudaEventElapsedTime(&milliseconds3, start3, stop3);\n        total_milliseconds3 += milliseconds3;\n    }\n    float average_milliseconds3 = total_milliseconds3 / num_runs;\n    cudaEventDestroy(start3);\n    cudaEventDestroy(stop3);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds3, average_milliseconds3 );\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"Shared Coalesced\");\n\n    cudaEvent_t start4, stop4;\n    cudaEventCreate(&start4);\n    cudaEventCreate(&stop4);\n    float total_milliseconds4 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start4);\n        shared_coalesced_bank_conflict<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop4);\n        cudaEventSynchronize(stop4);\n        float milliseconds4 = 0;\n        cudaEventElapsedTime(&milliseconds4, start4, stop4);\n        total_milliseconds4 += milliseconds4;\n    }\n    float average_milliseconds4 = total_milliseconds4 / num_runs;\n    cudaEventDestroy(start4);\n    cudaEventDestroy(stop4);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds4, average_milliseconds4 );\n\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"No Bank Conflict\");\n\n    cudaEvent_t start5, stop5;\n    cudaEventCreate(&start5);\n    cudaEventCreate(&stop5);\n    float total_milliseconds5 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start5);\n        shared_coalesced_no_bank_conflict<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop5);\n        cudaEventSynchronize(stop5);\n        float milliseconds5 = 0;\n        cudaEventElapsedTime(&milliseconds5, start5, stop5);\n        total_milliseconds5 += milliseconds5;\n    }\n    float average_milliseconds5 = total_milliseconds5 / num_runs;\n    cudaEventDestroy(start5);\n    cudaEventDestroy(stop5);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds5, average_milliseconds5 );\n\n\n\n    // for (int row = 0; row < 10; row ++){\n    //     for (int col = 0; col < 10; col++){\n    //         std::cout << c_data[row*cols + col] << \" \" ;\n    //     }\n    //     std::cout << \"\\n\";\n    // }\n\n    // std::cout << \"\\n\\n\";\n\n    // for (int row = 0; row < 10; row ++){\n    //     for (int col = 0; col < 10; col++){\n    //         std::cout << c_output[row*cols + col] << \" \" ;\n    //     }\n    //     std::cout << \"\\n\";\n    // }\n    \n    // Free memory\n    cudaFree(d_data);\n    cudaFree(d_output);\n    delete[] c_data;\n    delete[] c_output;\n\n\n    cudaDeviceReset(); // Important: Release CUDA resources\n    return 0;\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.880663Z","iopub.status.idle":"2025-03-07T07:02:39.880925Z","shell.execute_reply":"2025-03-07T07:02:39.880797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc t.cu -o t\n./t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.881680Z","iopub.status.idle":"2025-03-07T07:02:39.882005Z","shell.execute_reply":"2025-03-07T07:02:39.881841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pinned Memory","metadata":{}},{"cell_type":"code","source":"%%writefile t1.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\nconst int TILE_DIM = 32;\nconst int num_runs = 100;\n\n// Simple kernel to perform vector addition\n__global__ void matrix_copy(float* in_matrix, float* out_matrix, int n) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    int block_rows = blockDim.y;\n    int size = blockDim.x * gridDim.x; // as rows == cols\n    if (x < n && y < n)\n        for (int dim_y = 0; dim_y < gridDim.y; dim_y += block_rows){\n            out_matrix[(dim_y+ y)*size + x] = in_matrix[(dim_y+ y)*size + x];\n        }\n}\n\n__global__ void navie_transpose(float* in_matrix, float* out_matrix, int n) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    int block_rows = blockDim.y;\n    int size = blockDim.x * gridDim.x; // as rows == cols\n    if (x < n && y < n)\n        for (int dim_y = 0; dim_y < gridDim.y; dim_y += block_rows){\n            out_matrix[x*size + (dim_y + y)] = in_matrix[(dim_y + y)*size + x];\n        }\n\n}\n\n__global__ void shared_copy(float* in_matrix, float* out_matrix, int n) {\n    __shared__ float share[TILE_DIM * TILE_DIM];\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    // int block_rows = blockDim.y;\n    // int size = blockDim.x * gridDim.x; // as rows == cols\n    if (x < n && y < n)\n        share[(threadIdx.y)*blockDim.y + threadIdx.x] = in_matrix[(y)*n + x];\n        __syncthreads();\n        // for (int dim_y = 0; dim_y < gridDim.y; dim_y += block_rows)\n        {\n        out_matrix[(y)*n + x] = share[(threadIdx.x)*blockDim.x + threadIdx.y];\n        }\n\n    }\n\n__global__ void shared_coalesced_bank_conflict(float *in_matrix, float *out_matrix, int n){\n    __shared__ float tile[TILE_DIM][TILE_DIM];\n    int x = blockIdx.x*blockDim.x + threadIdx.x;\n    int y = blockIdx.y*blockDim.y + threadIdx.y;\n\n    int width = n;\n    if (x < n && y < n){\n        tile[threadIdx.y][threadIdx.x] = in_matrix[(y * width ) + threadIdx.x];\n    }\n    __syncthreads();\n    \n    x = blockIdx.y*blockDim.x + threadIdx.x;\n    y = blockIdx.x*blockDim.y + threadIdx.y;\n    if (x < n && y < n){\n        out_matrix[(y*width) + x] = tile[threadIdx.x][threadIdx.y];\n    }\n }\n\n __global__ void shared_coalesced_no_bank_conflict(float *in_matrix, float *out_matrix, int n){\n    __shared__ float tile[TILE_DIM][TILE_DIM + 1];\n    int x = blockIdx.x*blockDim.x + threadIdx.x;\n    int y = blockIdx.y*blockDim.y + threadIdx.y;\n\n    int width = n;\n    if (x < n && y < n){\n        tile[threadIdx.y][threadIdx.x] = in_matrix[(y * width ) + threadIdx.x];\n    }\n    __syncthreads();\n    \n    x = blockIdx.y*blockDim.x + threadIdx.x;\n    y = blockIdx.x*blockDim.y + threadIdx.y;\n    if (x < n && y < n){\n        out_matrix[(y*width) + x] = tile[threadIdx.x][threadIdx.y];\n    }\n }\n\nint main() {\n    int rows = 1024;\n    int cols = 1024;\n    int size = rows * cols; \n    float *c_data, *c_output; // Host arrays\n    float *d_data, *d_output; // Device arrays\n\n    // Allocate memory on host\n    c_data = new float[size];\n    c_output = new float[size];\n\n    // Allocate memory on device\n    cudaMallocHost((void **)&d_data, size * sizeof(float));\n    cudaMallocHost((void **)&d_output, size * sizeof(float));\n    // cudaMallocHost creates a pinned memory, avoids the overhead of pageable -> pinned memory\n\n    // Initialize host arrays (example values)\n    for (int row = 0; row < rows; row ++){\n        for (int col = 0; col < cols; col++){\n            c_data[row*cols + col] = row*cols + col;\n        }\n    }\n\n    // Copy data from host to device\n    cudaMemcpy(d_data, c_data, size * sizeof(float), cudaMemcpyHostToDevice);\n\n\n    // Kernel launch configuration\n    dim3 blockSize(32, 32, 1);\n    dim3 gridSize(32, 32, 1);\n\n    printf(\"%25s%25s%25s\\n\", \"Exectution\", \"Bandwidth (GB/s)\", \"GPU Time (ms)\");\n    printf(\"\\n\");\n\n    printf(\"%25s\",\"Matrix Copy\");\n\n    cudaEvent_t start1, stop1;\n    cudaEventCreate(&start1);\n    cudaEventCreate(&stop1);\n    float total_milliseconds1 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start1);\n        matrix_copy<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        //navie_transpose<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop1);\n        cudaEventSynchronize(stop1);\n        float milliseconds1 = 0;\n        cudaEventElapsedTime(&milliseconds1, start1, stop1);\n        total_milliseconds1 += milliseconds1;\n    }\n    float average_milliseconds1 = total_milliseconds1 / num_runs;\n    cudaEventDestroy(start1);\n    cudaEventDestroy(stop1);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds1, average_milliseconds1 );\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"Shared Copy\");\n\n    cudaEvent_t start2, stop2;\n    cudaEventCreate(&start2);\n    cudaEventCreate(&stop2);\n    \n    float total_milliseconds2 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start2);\n        shared_copy<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop2);\n        cudaEventSynchronize(stop2);\n        float milliseconds2 = 0;\n        cudaEventElapsedTime(&milliseconds2, start2, stop2);\n        total_milliseconds2 += milliseconds2;\n    }\n    float average_milliseconds2 = total_milliseconds2 / num_runs;\n    cudaEventDestroy(start2);\n    cudaEventDestroy(stop2);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds2, average_milliseconds2 );\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"Navie Transpose\");\n\n    cudaEvent_t start3, stop3;\n    cudaEventCreate(&start3);\n    cudaEventCreate(&stop3);\n    float total_milliseconds3 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start3);\n        navie_transpose<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop3);\n        cudaEventSynchronize(stop3);\n        float milliseconds3 = 0;\n        cudaEventElapsedTime(&milliseconds3, start3, stop3);\n        total_milliseconds3 += milliseconds3;\n    }\n    float average_milliseconds3 = total_milliseconds3 / num_runs;\n    cudaEventDestroy(start3);\n    cudaEventDestroy(stop3);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds3, average_milliseconds3 );\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"Shared Coalesced\");\n\n    cudaEvent_t start4, stop4;\n    cudaEventCreate(&start4);\n    cudaEventCreate(&stop4);\n    float total_milliseconds4 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start4);\n        shared_coalesced_bank_conflict<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop4);\n        cudaEventSynchronize(stop4);\n        float milliseconds4 = 0;\n        cudaEventElapsedTime(&milliseconds4, start4, stop4);\n        total_milliseconds4 += milliseconds4;\n    }\n    float average_milliseconds4 = total_milliseconds4 / num_runs;\n    cudaEventDestroy(start4);\n    cudaEventDestroy(stop4);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds4, average_milliseconds4 );\n\n\n\n    /*  -----------------------  */\n\n    printf(\"%25s\",\"No Bank Conflict\");\n\n    cudaEvent_t start5, stop5;\n    cudaEventCreate(&start5);\n    cudaEventCreate(&stop5);\n    float total_milliseconds5 = 0;\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start5);\n        shared_coalesced_no_bank_conflict<<<gridSize, blockSize>>>(d_data, d_output, rows);\n        cudaEventRecord(stop5);\n        cudaEventSynchronize(stop5);\n        float milliseconds5 = 0;\n        cudaEventElapsedTime(&milliseconds5, start5, stop5);\n        total_milliseconds5 += milliseconds5;\n    }\n    float average_milliseconds5 = total_milliseconds5 / num_runs;\n    cudaEventDestroy(start5);\n    cudaEventDestroy(stop5);\n    cudaMemcpy(c_output, d_output, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds5, average_milliseconds5 );\n\n\n\n    // for (int row = 0; row < 10; row ++){\n    //     for (int col = 0; col < 10; col++){\n    //         std::cout << c_data[row*cols + col] << \" \" ;\n    //     }\n    //     std::cout << \"\\n\";\n    // }\n\n    // std::cout << \"\\n\\n\";\n\n    // for (int row = 0; row < 10; row ++){\n    //     for (int col = 0; col < 10; col++){\n    //         std::cout << c_output[row*cols + col] << \" \" ;\n    //     }\n    //     std::cout << \"\\n\";\n    // }\n    \n    // Free memory\n    cudaFree(d_data);\n    cudaFree(d_output);\n    delete[] c_data;\n    delete[] c_output;\n\n\n    cudaDeviceReset(); // Important: Release CUDA resources\n    return 0;\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.882552Z","iopub.status.idle":"2025-03-07T07:02:39.882877Z","shell.execute_reply":"2025-03-07T07:02:39.882709Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc t1.cu -o t1\n./t1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.883476Z","iopub.status.idle":"2025-03-07T07:02:39.883743Z","shell.execute_reply":"2025-03-07T07:02:39.883639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day XX , (March 2, 2025)","metadata":{}},{"cell_type":"code","source":"1. define block size and grid size\n    - block = (32, 32)\n    - grid = (cols+blocksize-1/blocksize)\n    - tile_width = 32\n\n\n    bx, by\n    tx, ty\n\n    Mds, Nds\n\n    Mds[ty][tx] = A[blockIdx.x * blockDim.x + tx]\n    Nds[ty][tx]\n\n    M[by*bdim*width + ty*width + tx ]\n    N[bx*bdim + (ty*width) + tx]\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.884468Z","iopub.status.idle":"2025-03-07T07:02:39.884718Z","shell.execute_reply":"2025-03-07T07:02:39.884617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"M = [[1,2,3], [4,5,6], [7,8,9]]\nN = [[3,2,1], [6,5,4], [9,8,7]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.885506Z","iopub.status.idle":"2025-03-07T07:02:39.885787Z","shell.execute_reply":"2025-03-07T07:02:39.885684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile shared_mat_mul.cu\n\n#include <iostream>\n#include <cuda_runtime.h>\n\n# define TILE_WIDTH 32\n\n__global__ void navie_mat_mul(float *P_A, float *P_B,float *P_C, int Width){\n    int row = blockDim.y*blockIdx.y + threadIdx.y;\n    int col = blockDim.x*blockIdx.x + threadIdx.x;\n\n    if (row < Width && col < Width){\n        for (int k=0; k<Width; k++){\n            P_C[row*Width+col] += P_A[row*Width+k] * P_B[k*Width+col];\n        }\n    }\n}\n\n__global__ void  mat_mul(float *A, float *B, float *C, int width){\n    __shared__ float As[TILE_WIDTH][TILE_WIDTH];\n    __shared__ float Bs[TILE_WIDTH][TILE_WIDTH];\n\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    int row = by * TILE_WIDTH + ty;\n    int col = bx * TILE_WIDTH + tx;\n\n    float element_value = 0;\n\n    for (int t=0; t < int (width+TILE_WIDTH - 1)/TILE_WIDTH; t ++){\n\n        if ((row < width) && ((t*TILE_WIDTH + tx) < width)){\n            As[ty][tx] = A[row*width + t*TILE_WIDTH + tx];\n        }\n        else{\n            As[ty][tx] = 0.0f;\n        }\n    \n        if ((col < width) && ((t*TILE_WIDTH + ty) < width)){\n            Bs[ty][tx] = B[(t*TILE_WIDTH + ty)*width + col];\n        }\n        else{\n            Bs[ty][tx] = 0.0f;\n        }\n        __syncthreads();\n\n        \n        for (int k=0; k < TILE_WIDTH; k++){\n            element_value += As[ty][k]* Bs[k][tx];\n        }\n        __syncthreads();\n\n    }\n    if ((row < width) && (col < width)){\n        C[row*width + col] = element_value;\n    }\n\n}\n\n\nint main(){\n    int rows = 1024;\n    int cols = 1024;\n    int size = rows * cols; \n    float *hA, *hB, *hC, *hC_naive; // Host arrays\n    float *dA, *dB, *dC, *dC_naive; // Device arrays\n\n    // Allocate memory on host\n    hA = new float[size];\n    hB = new float[size];\n    hC = new float[size];\n    hC_naive = new float[size];\n\n    // Allocate memory on device\n    cudaMalloc((void **)&dA, size * sizeof(float));\n    cudaMalloc((void **)&dB, size * sizeof(float));\n    cudaMalloc((void **)&dC, size * sizeof(float));\n\n    cudaMalloc((void **)&dC_naive, size * sizeof(float));\n\n    // Initialize host arrays (example values)\n    for (int row = 0; row < rows; row ++){\n        for (int col = 0; col < cols; col++){\n            // hA[row*cols + col] = row*cols + col;\n            hA[row*cols + col] = 1;\n        }\n    }\n\n    // Initialize host arrays (example values)\n    for (int row = 0; row < rows; row ++){\n        for (int col = 0; col < cols; col++){\n            // hB[row*cols + col] = row*cols + col;\n            hB[row*cols + col] = 1;\n        }\n    }\n\n    // Copy data from host to device\n    cudaMemcpy(dA, hA, size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(dB, hB, size * sizeof(float), cudaMemcpyHostToDevice);\n\n\n    // Kernel launch configuration\n    dim3 blockSize(TILE_WIDTH, TILE_WIDTH, 1);\n    dim3 gridSize((cols + TILE_WIDTH - 1) / TILE_WIDTH, (rows + TILE_WIDTH - 1) / TILE_WIDTH, 1);\n\n    printf(\"%25s%25s%25s\\n\", \"Exectution\", \"Bandwidth (GB/s)\", \"GPU Time (ms)\");\n    printf(\"\\n\");\n\n    printf(\"%25s\",\"Matrix Mul\");\n\n    cudaEvent_t start1, stop1;\n    cudaEventCreate(&start1);\n    cudaEventCreate(&stop1);\n    float total_milliseconds1 = 0;\n    int num_runs = 100;\n\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start1);\n        mat_mul<<<gridSize, blockSize>>>(dA, dB, dC, rows);\n        cudaEventRecord(stop1);\n        cudaEventSynchronize(stop1);\n        float milliseconds1 = 0;\n        cudaEventElapsedTime(&milliseconds1, start1, stop1);\n        total_milliseconds1 += milliseconds1;\n    }\n    float average_milliseconds1 = total_milliseconds1 / num_runs;\n    cudaEventDestroy(start1);\n    cudaEventDestroy(stop1);\n    cudaMemcpy(hC, dC, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds1, average_milliseconds1 );\n\n\n    \n    printf(\"%25s\",\"Navie Matrix Mul\");\n\n    cudaEvent_t start2, stop2;\n    cudaEventCreate(&start2);\n    cudaEventCreate(&stop2);\n    float total_milliseconds2 = 0;\n    int num_runs1 = 100;\n\n    for (int i=0; i < num_runs1; i++){\n        cudaEventRecord(start2);\n        navie_mat_mul<<<gridSize, blockSize>>>(dA, dB, dC_naive, rows);\n        cudaEventRecord(stop2);\n        cudaEventSynchronize(stop2);\n        float milliseconds2 = 0;\n        cudaEventElapsedTime(&milliseconds2, start2, stop2);\n        total_milliseconds2 += milliseconds2;\n    }\n    float average_milliseconds2 = total_milliseconds2 / num_runs1;\n    cudaEventDestroy(start2);\n    cudaEventDestroy(stop2);\n    cudaMemcpy(hC_naive, dC_naive, size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds2, average_milliseconds2 );\n\n    \n    printf(\"hA: \\n \");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.0f \", hA[row*cols + col]);\n        }\n        printf(\"\\n\");\n    }\n    \n    printf(\"hB: \\n\");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.0f \", hB[row*cols + col]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\\n\");\n    printf(\"hC: \\n\");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.f \", hC[row*cols + col]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\\n\");\n    printf(\"hC_naive: \\n\");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.f \", hC_naive[row*cols + col]/num_runs1);\n        }\n        printf(\"\\n\");\n    }\n    return 0;\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.886607Z","iopub.status.idle":"2025-03-07T07:02:39.886869Z","shell.execute_reply":"2025-03-07T07:02:39.886744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc ./shared_mat_mul.cu -o t\n./t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.887553Z","iopub.status.idle":"2025-03-07T07:02:39.887859Z","shell.execute_reply":"2025-03-07T07:02:39.887688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile mul.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\n# define TILE_WIDTH 32\n\n__global__ void navie_mat_mul(float *P_A, float *P_B,float *P_C, int Width){\n    int row = blockDim.y*blockIdx.y + threadIdx.y;\n    int col = blockDim.x*blockIdx.x + threadIdx.x;\n\n    if (row < Width && col < Width){\n        for (int k=0; k<Width; k++){\n            P_C[row*Width+col] += P_A[row*Width+k] * P_B[k*Width+col];\n        }\n    }\n}\n\n__global__ void  mat_mul(float *A, float *B, float *C, int width){\n    __shared__ float As[TILE_WIDTH][TILE_WIDTH];\n    __shared__ float Bs[TILE_WIDTH][TILE_WIDTH];\n\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    int row = by * TILE_WIDTH + ty;\n    int col = bx * TILE_WIDTH + tx;\n\n    float element_value = 0;\n\n    for (int t=0; t < int (width+TILE_WIDTH - 1)/TILE_WIDTH; t ++){\n\n        if ((row < width) && ((t*TILE_WIDTH + tx) < width)){\n            As[ty][tx] = A[row*width + t*TILE_WIDTH + tx];\n        }\n        else{\n            As[ty][tx] = 0.0f;\n        }\n    \n        if ((col < width) && ((t*TILE_WIDTH + ty) < width)){\n            Bs[ty][tx] = B[(t*TILE_WIDTH + ty)*width + col];\n        }\n        else{\n            Bs[ty][tx] = 0.0f;\n        }\n        __syncthreads();\n\n        \n        for (int k=0; k < TILE_WIDTH; k++){\n            element_value += As[ty][k]* Bs[k][tx];\n        }\n        __syncthreads();\n\n    }\n    if ((row < width) && (col < width)){\n        C[row*width + col] = element_value;\n    }\n\n}\n\n\nint main(){\n    int rows = 2048;\n    int cols = 2048;\n    int size = rows * cols; \n    float *hA, *hB, *hC, *hC_naive; // Host arrays\n    float *dA, *dB, *dC, *dC_naive; // Device arrays\n\n    // Allocate memory on host\n    hA = new float[size];\n    hB = new float[size];\n    hC = new float[size];\n    hC_naive = new float[size];\n\n    // Allocate memory on device\n    cudaMalloc((void **)&dA, size * sizeof(float));\n    cudaMalloc((void **)&dB, size * sizeof(float));\n    cudaMalloc((void **)&dC, size * sizeof(float));\n\n    cudaMalloc((void **)&dC_naive, size * sizeof(float));\n\n    // Initialize host arrays (example values)\n    for (int row = 0; row < rows; row ++){\n        for (int col = 0; col < cols; col++){\n            // hA[row*cols + col] = row*cols + col;\n            hA[row*cols + col] = 1;\n        }\n    }\n\n    // Initialize host arrays (example values)\n    for (int row = 0; row < rows; row ++){\n        for (int col = 0; col < cols; col++){\n            // hB[row*cols + col] = row*cols + col;\n            hB[row*cols + col] = 1;\n        }\n    }\n\n    // Copy data from host to device\n    cudaMemcpy(dA, hA, size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(dB, hB, size * sizeof(float), cudaMemcpyHostToDevice);\n\n\n    // Kernel launch configuration\n    dim3 blockSize(TILE_WIDTH, TILE_WIDTH, 1);\n    dim3 gridSize((cols + TILE_WIDTH - 1) / TILE_WIDTH, (rows + TILE_WIDTH - 1) / TILE_WIDTH, 1);\n\n    printf(\"%25s%25s%25s\\n\", \"Exectution\", \"Bandwidth (GB/s)\", \"GPU Time (ms)\");\n    printf(\"\\n\");\n\n    printf(\"%25s\",\"Matrix Mul\");\n\n    cudaEvent_t start1, stop1;\n    cudaEventCreate(&start1);\n    cudaEventCreate(&stop1);\n    float total_milliseconds1 = 0;\n    int num_runs = 1;\n\n    for (int i=0; i < num_runs; i++){\n        cudaEventRecord(start1);\n        mat_mul<<<gridSize, blockSize>>>(dA, dB, dC, rows);\n        cudaEventRecord(stop1);\n        cudaEventSynchronize(stop1);\n        float milliseconds1 = 0;\n        cudaEventElapsedTime(&milliseconds1, start1, stop1);\n        total_milliseconds1 += milliseconds1;\n    }\n    float average_milliseconds1 = total_milliseconds1 / num_runs;\n    cudaEventDestroy(start1);\n    cudaEventDestroy(stop1);\n    cudaMemcpy(hC, dC, size * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f%25.4f\\n\", 2 * (size) * sizeof(float)* 1e-6 / average_milliseconds1, average_milliseconds1 );\n\n\n    \n    printf(\"%25s\",\"Navie Matrix Mul\");\n\n    cudaEvent_t start2, stop2;\n    cudaEventCreate(&start2);\n    cudaEventCreate(&stop2);\n    float total_milliseconds2 = 0;\n    int num_runs1 = 1;\n\n    for (int i=0; i < num_runs1; i++){\n        cudaEventRecord(start2);\n        navie_mat_mul<<<gridSize, blockSize>>>(dA, dB, dC_naive, rows);\n        cudaEventRecord(stop2);\n        cudaEventSynchronize(stop2);\n        float milliseconds2 = 0;\n        cudaEventElapsedTime(&milliseconds2, start2, stop2);\n        total_milliseconds2 += milliseconds2;\n    }\n    float average_milliseconds2 = total_milliseconds2 / num_runs1;\n    cudaEventDestroy(start2);\n    cudaEventDestroy(stop2);\n    cudaMemcpy(hC_naive, dC_naive, size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    printf(\"%20.4f%25.4f\\n\", 2 * size * sizeof(float)* 1e-6 / average_milliseconds2, average_milliseconds2 );\n\n    \n    printf(\"hA: \\n \");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.0f \", hA[row*cols + col]);\n        }\n        printf(\"\\n\");\n    }\n    \n    printf(\"hB: \\n\");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.0f \", hB[row*cols + col]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\\n\");\n    printf(\"hC: \\n\");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.f \", hC[row*cols + col]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\\n\");\n    printf(\"hC_naive: \\n\");\n    for (int row = 0; row < 5; row ++){\n        for (int col = 0; col < 5; col++){\n            printf(\"%0.f \", hC_naive[row*cols + col]/num_runs1);\n        }\n        printf(\"\\n\");\n    }\n    return 0;\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.888462Z","iopub.status.idle":"2025-03-07T07:02:39.888785Z","shell.execute_reply":"2025-03-07T07:02:39.888626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc ./mul.cu -o t\nnvprof ./t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:02:39.889395Z","iopub.status.idle":"2025-03-07T07:02:39.889718Z","shell.execute_reply":"2025-03-07T07:02:39.889589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Convolution","metadata":{}},{"cell_type":"code","source":"%%writefile convolution.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\n#define filter_radius 2\n#define tile_dim 32\n\n__constant__ float hC[(2*filter_radius + 1)*(2*filter_radius + 1)];\n\n__global__ void conv2d(float *inp, float *filt, float * oup, int rows, int cols){\n    int gty = blockIdx.x * blockDim.x + threadIdx.x;\n    int gtx = blockIdx.y * blockDim.y + threadIdx.y;\n\n    float accumulate = 0;\n    for (int fr = -1*filter_radius; fr < filter_radius+1; fr++){\n        for (int fc = -1*filter_radius; fc < filter_radius+1; fc++){\n            int gtx_new = gtx+fr;\n            int gty_new = gty+fc;\n            if (gtx_new >= 0 && gtx_new < rows && gty_new >= 0 && gty_new < cols){\n\n                int abs_fr = fr + filter_radius;\n                int abs_fc = fc + filter_radius;\n                \n                accumulate += filt[abs_fr * (2*filter_radius + 1) + abs_fc] * inp[gtx_new*cols + gty_new];\n                \n            }\n        }\n    oup[gtx*cols + gty] = accumulate;\n    }\n}\n\n\n__global__ void conv2d_with_constant_memory(float *inp, float * oup, int rows, int cols){\n    int gty = blockIdx.x * blockDim.x + threadIdx.x;\n    int gtx = blockIdx.y * blockDim.y + threadIdx.y;\n\n    float accumulate = 0;\n    for (int fr = -1*filter_radius; fr < filter_radius+1; fr++){\n        for (int fc = -1*filter_radius; fc < filter_radius+1; fc++){\n            int gtx_new = gtx+fr;\n            int gty_new = gty+fc;\n            if (gtx_new >= 0 && gtx_new < rows && gty_new >= 0 && gty_new < cols){\n\n                int abs_fr = fr + filter_radius;\n                int abs_fc = fc + filter_radius;\n                \n                accumulate += hC[abs_fr * (2*filter_radius + 1) + abs_fc] * inp[gtx_new*cols + gty_new];\n                \n            }\n        }\n    oup[gtx*cols + gty] = accumulate;\n    }\n}\n\n\n__global__ void conv2d_with_constant_memory_shared_memory(float *inp, float * oup, int rows, int cols){\n\n    __shared__ int shared_tile[tile_dim][tile_dim+1];\n    \n    int gty = blockIdx.x * blockDim.x + threadIdx.x;\n    int gtx = blockIdx.y * blockDim.y + threadIdx.y;\n\n    shared_tile[threadIdx.y][threadIdx.x] = inp[gtx*rows + gty];\n    __syncthreads();\n\n    float accumulate = 0;\n    for (int fr = -1*filter_radius; fr < filter_radius+1; fr++){\n        for (int fc = -1*filter_radius; fc < filter_radius+1; fc++){\n            // int gtx_new = gtx+fr;\n            // int gty_new = gty+fc;\n            // if (gtx_new >= 0 && gtx_new < rows && gty_new >= 0 && gty_new < cols){\n\n            int abs_fr = fr + filter_radius;\n            int abs_fc = fc + filter_radius;\n            float tid_y_fc = threadIdx.y + fc;\n            float tid_x_fr = threadIdx.x + fr;\n\n            if (tid_y_fc >= 0 && tid_y_fc < tile_dim && tid_x_fr >= 0 && tid_x_fr < tile_dim ){\n                accumulate += hC[abs_fr * (2*filter_radius + 1) + abs_fc] * shared_tile[threadIdx.y + fc][threadIdx.x + fr];\n            }\n                \n        }\n    oup[gtx*rows + gty] = accumulate;\n    }\n}\n\nint main(){\n    int rows = 1024;\n    int cols = 1024;\n\n    // int filter_radius = 2;\n\n    float *hA, *hB, *hFilt;\n    float *dA, *dB, *dC;\n\n    hA = new float[rows*cols];\n    hB = new float[rows*cols];\n    hFilt = new float[(2*filter_radius + 1)*(2*filter_radius + 1)]; //filter\n\n    cudaMalloc((void**)&dA,  rows*cols*sizeof(float));\n    cudaMalloc((void**)&dB,  rows*cols*sizeof(float));\n    cudaMalloc((void**)&dC,  rows*cols*sizeof(float));\n\n    for (int i=0; i < rows; i++){\n        for (int j=0; j < cols; j++){\n            hA[i*cols + j] = 1;\n        }\n    }\n\n    for (int i=0; i < 2*filter_radius + 1; i++){\n        for (int j=0; j < 2*filter_radius + 1; j++){\n            if (i == filter_radius || j == filter_radius){\n                hFilt[i*(2*filter_radius + 1) + j] = 1;\n            }\n            else{\n                hFilt[i*(2*filter_radius + 1) + j] = 0;\n            }\n        }\n    }\n\n    cudaMemcpy(dA, hA, rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(dB, hB, rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(dC, hFilt, (2*filter_radius + 1)*(2*filter_radius + 1) * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpyToSymbol(hC, hFilt, (2*filter_radius + 1)*(2*filter_radius + 1) * sizeof(float));\n\n\n    dim3 block_size(tile_dim, tile_dim);\n    dim3 grid_size((cols + block_size.x - 1)/block_size.x, (rows + block_size.y - 1)/block_size.y);\n    int num_runs = 100;\n\n    cudaEvent_t start1, stop1;\n    cudaEventCreate(&start1);\n    cudaEventCreate(&stop1);\n    float total_ms1 = 0;\n\n    printf(\"%25s%25s\\n\", \"Exectution\", \"GPU Time (ms)\");\n    printf(\"\\n\");\n\n    printf(\"%25s\", \"Naive Conv 2D\");\n\n    for (int i=0; i< num_runs; i++){\n        cudaEventRecord(start1);\n        conv2d<<<grid_size, block_size>>>(dA, dC, dB, rows, cols);\n        cudaEventRecord(stop1);\n        cudaEventSynchronize(stop1);\n        float milliseconds1 = 0;\n        cudaEventElapsedTime(&milliseconds1, start1, stop1);\n        total_ms1 += milliseconds1;\n    }\n    float average_milliseconds1 = total_ms1 / num_runs;\n    cudaEventDestroy(start1);\n    cudaEventDestroy(stop1);\n    cudaMemcpy(hB, dB, rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f\", average_milliseconds1 );\n    \n    printf(\"\\n\");\n    printf(\"%25s\", \"Constant Memory Conv 2D\");\n    cudaEvent_t start2, stop2;\n    cudaEventCreate(&start2);\n    cudaEventCreate(&stop2);\n    float total_ms2 = 0;\n    for (int i=0; i< num_runs; i++){\n        cudaEventRecord(start2);\n        conv2d_with_constant_memory<<<grid_size, block_size>>>(dA, dB, rows, cols);\n        cudaEventRecord(stop2);\n        cudaEventSynchronize(stop2);\n        float milliseconds2 = 0;\n        cudaEventElapsedTime(&milliseconds2, start2, stop2);\n        total_ms2 += milliseconds2;\n    }\n    float average_milliseconds2 = total_ms2 / num_runs;\n    cudaEventDestroy(start2);\n    cudaEventDestroy(stop2);\n    cudaMemcpy(hB, dB, rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%20.4f\", average_milliseconds2 );\n\n\n    printf(\"\\n\");\n    printf(\"%25s\", \"Shared & Const Memory Conv 2D\");\n    cudaEvent_t start3, stop3;\n    cudaEventCreate(&start3);\n    cudaEventCreate(&stop3);\n    float total_ms3 = 0;\n    for (int i=0; i< num_runs; i++){\n        cudaEventRecord(start3);\n        conv2d_with_constant_memory_shared_memory<<<grid_size, block_size>>>(dA, dB, rows, cols);\n        cudaEventRecord(stop3);\n        cudaEventSynchronize(stop3);\n        float milliseconds3 = 0;\n        cudaEventElapsedTime(&milliseconds3, start3, stop3);\n        total_ms3 += milliseconds3;\n    }\n    float average_milliseconds3 = total_ms3 / num_runs;\n    cudaEventDestroy(start3);\n    cudaEventDestroy(stop3);\n    cudaMemcpy(hB, dB, rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"%17.4f\", average_milliseconds3 );\n\n\n\n    // conv2d_with_constant_memory_shared_memory\n    // printf(\"\\nhB: \\n\");\n    // for (int row = 0; row < 32; row ++){\n    //     for (int col = 0; col < 32; col++){\n    //         printf(\"%0.0f \", hB[row*cols + col]);\n    //     }\n    //     printf(\"\\n\");\n    // }\n    return 0;   \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T19:38:05.342266Z","iopub.execute_input":"2025-03-08T19:38:05.342541Z","iopub.status.idle":"2025-03-08T19:38:05.348203Z","shell.execute_reply.started":"2025-03-08T19:38:05.342518Z","shell.execute_reply":"2025-03-08T19:38:05.347346Z"}},"outputs":[{"name":"stdout","text":"Overwriting convolution.cu\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"%%script bash\nnvcc ./convolution.cu -o t1\nnvprof ./t1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T19:38:08.377394Z","iopub.execute_input":"2025-03-08T19:38:08.377721Z","iopub.status.idle":"2025-03-08T19:38:10.721986Z","shell.execute_reply.started":"2025-03-08T19:38:08.377692Z","shell.execute_reply":"2025-03-08T19:38:10.721139Z"}},"outputs":[{"name":"stdout","text":"               Exectution            GPU Time (ms)\n\n            Naive Conv 2D              0.2227\n  Constant Memory Conv 2D              0.1699\nShared & Const Memory Conv 2D           0.1478","output_type":"stream"},{"name":"stderr","text":"==949== NVPROF is profiling process 949, command: ./t1\n==949== Profiling application: ./t1\n==949== Profiling result:\n            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n GPU activities:   36.79%  21.696ms       100  216.96us  216.35us  217.50us  conv2d(float*, float*, float*, int, int)\n                   27.83%  16.415ms       100  164.15us  163.01us  165.47us  conv2d_with_constant_memory(float*, float*, int, int)\n                   24.06%  14.187ms       100  141.87us  138.53us  144.38us  conv2d_with_constant_memory_shared_memory(float*, float*, int, int)\n                    7.00%  4.1282ms         3  1.3761ms  606.55us  2.9037ms  [CUDA memcpy DtoH]\n                    4.32%  2.5481ms         4  637.03us     672ns  1.8039ms  [CUDA memcpy HtoD]\n      API calls:   60.67%  105.24ms         3  35.080ms  111.77us  104.98ms  cudaMalloc\n                   31.06%  53.881ms       300  179.60us  140.32us  230.36us  cudaEventSynchronize\n                    6.24%  10.823ms         6  1.8039ms  92.354us  5.5384ms  cudaMemcpy\n                    0.79%  1.3762ms       300  4.5870us  3.2690us  25.818us  cudaLaunchKernel\n                    0.50%  869.90us       600  1.4490us  1.1990us  5.5930us  cudaEventRecord\n                    0.31%  537.78us         1  537.78us  537.78us  537.78us  cudaMemcpyToSymbol\n                    0.24%  415.23us       228  1.8210us     131ns  93.666us  cuDeviceGetAttribute\n                    0.15%  268.72us       300     895ns     835ns  1.9170us  cudaEventElapsedTime\n                    0.01%  19.445us         6  3.2400us     655ns  8.8710us  cudaEventCreate\n                    0.01%  16.561us         2  8.2800us  5.5550us  11.006us  cuDeviceGetName\n                    0.01%  9.7880us         2  4.8940us  2.1140us  7.6740us  cuDeviceGetPCIBusId\n                    0.00%  5.7240us         6     954ns     454ns  1.5300us  cudaEventDestroy\n                    0.00%  1.4920us         4     373ns     137ns     783ns  cuDeviceGet\n                    0.00%  1.3020us         3     434ns     168ns     836ns  cuDeviceGetCount\n                    0.00%     806ns         2     403ns     313ns     493ns  cuDeviceTotalMem\n                    0.00%     657ns         1     657ns     657ns     657ns  cuModuleGetLoadingMode\n                    0.00%     597ns         2     298ns     203ns     394ns  cuDeviceGetUuid\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"## Convolution\n1. **Naive Convolution**\n   -  a simple element-wise multiplication and summation within the filter window. \n   -  global memory access of the filter elements and input matrix\n2. **Convolution with constant memory**\n   -  here we are creating a constant memory, it is a special, read-only memory space on the GPU designed for storing data that remains constant during the execution of a kernel.\n   -  used to store data that is read by many threads but does not change during the kernel's execution. This makes it good for storing coefficients, lookup tables, or other fixed parameters.\n   -  Constant memory is cached on the GPU, which can significantly improve performance when all threads (or threads within a warp) access the same memory location.  \n      Once initialized by the host (CPU), the GPU threads can only read from constant memory. There's a limited amount of constant memory available (typically 64KB).\n   -  Still we are performing global memory access of the input element. This can be further optimized with shared memory where a tile in a block can save elements which can be read by all the           threads in a block.\n3. **Shared and Constant Memory**\n   -  Shared memory is used to reduce redundant global loads by reusing data, this reside on the GPU.\n   -  Here the difference in execution is not significant in comparison to filter constant memory execution. one of the reason may be due to __syncthreads(); which holds the thread operations            until all threads in a block finishes exectuion until each thread in a block reaches __syncthreads(); there are other factors like tile/filter size, persistent memory bandwidth limits, and         implementation efficiency.\n\n```\n    Exectution            GPU Time (ms)\n    \n                Naive Conv 2D              0.2227\n      Constant Memory Conv 2D              0.1699\n    Shared & Const Memory Conv 2D           0.1478\n    ==949== NVPROF is profiling process 949, command: ./t1\n    ==949== Profiling application: ./t1\n    ==949== Profiling result:\n                Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n     GPU activities:   36.79%  21.696ms       100  216.96us  216.35us  217.50us  conv2d(float*, float*, float*, int, int)\n                       27.83%  16.415ms       100  164.15us  163.01us  165.47us  conv2d_with_constant_memory(float*, float*, int, int)\n                       24.06%  14.187ms       100  141.87us  138.53us  144.38us  conv2d_with_constant_memory_shared_memory(float*, float*, int, int)\n                        7.00%  4.1282ms         3  1.3761ms  606.55us  2.9037ms  [CUDA memcpy DtoH]\n                        4.32%  2.5481ms         4  637.03us     672ns  1.8039ms  [CUDA memcpy HtoD]\n```\n\n\n**Next Steps**\n1. check for generalizing to rows != cols\n2. check thread coarsening on performance\n3. compute the memory bandwidth\n4. reread PMPP convolution for other performance methods\n5. remove the extra cells on the output matrix, here the size of input and output matrixs are same\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}