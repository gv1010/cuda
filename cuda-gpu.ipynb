{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:00:48.811597Z","iopub.status.idle":"2025-02-17T18:00:48.811990Z","shell.execute_reply":"2025-02-17T18:00:48.811802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python --version\n!nvcc --version\n!pip install nvcc4jupyter\n%load_ext nvcc4jupyter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T07:48:24.138919Z","iopub.execute_input":"2025-02-18T07:48:24.139166Z","iopub.status.idle":"2025-02-18T07:49:41.271013Z","shell.execute_reply.started":"2025-02-18T07:48:24.139145Z","shell.execute_reply":"2025-02-18T07:49:41.269979Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.12\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Tue_Aug_15_22:02:13_PDT_2023\nCuda compilation tools, release 12.2, V12.2.140\nBuild cuda_12.2.r12.2/compiler.33191640_0\nCollecting nvcc4jupyter\n  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\nDownloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\nInstalling collected packages: nvcc4jupyter\nSuccessfully installed nvcc4jupyter-1.2.1\nDetected platform \"Kaggle\". Running its setup...\nUpdating the package lists...\nInstalling nvidia-cuda-toolkit, this may take a few minutes...\nSource files will be saved in \"/tmp/tmpmt2pxmi9\".\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T07:49:41.272029Z","iopub.execute_input":"2025-02-18T07:49:41.272386Z","iopub.status.idle":"2025-02-18T07:49:41.390656Z","shell.execute_reply.started":"2025-02-18T07:49:41.272344Z","shell.execute_reply":"2025-02-18T07:49:41.389923Z"}},"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Tue_Aug_15_22:02:13_PDT_2023\nCuda compilation tools, release 12.2, V12.2.140\nBuild cuda_12.2.r12.2/compiler.33191640_0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!g++ -v","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T07:49:41.391527Z","iopub.execute_input":"2025-02-18T07:49:41.391789Z","iopub.status.idle":"2025-02-18T07:49:41.516411Z","shell.execute_reply.started":"2025-02-18T07:49:41.391756Z","shell.execute_reply":"2025-02-18T07:49:41.515661Z"}},"outputs":[{"name":"stdout","text":"Using built-in specs.\nCOLLECT_GCC=g++\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/11/lto-wrapper\nOFFLOAD_TARGET_NAMES=nvptx-none:amdgcn-amdhsa\nOFFLOAD_TARGET_DEFAULT=1\nTarget: x86_64-linux-gnu\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 11.4.0-1ubuntu1~22.04' --with-bugurl=file:///usr/share/doc/gcc-11/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,m2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-11 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --enable-libphobos-checking=release --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --enable-cet --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none=/build/gcc-11-XeT9lY/gcc-11-11.4.0/debian/tmp-nvptx/usr,amdgcn-amdhsa=/build/gcc-11-XeT9lY/gcc-11-11.4.0/debian/tmp-gcn/usr --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu --with-build-config=bootstrap-lto-lean --enable-link-serialization=2\nThread model: posix\nSupported LTO compression algorithms: zlib zstd\ngcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%writefile cpphw.hpp\n\n#include <iostream>\n\nvoid printHelloWorld()\n\n{\n\nstd::cout << \"HelloWorld\\nHelloWorld\";\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:52:02.460501Z","iopub.execute_input":"2025-02-16T08:52:02.460811Z","iopub.status.idle":"2025-02-16T08:52:02.466794Z","shell.execute_reply.started":"2025-02-16T08:52:02.460774Z","shell.execute_reply":"2025-02-16T08:52:02.466012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile cpphw.cpp\n\n#include \"cpphw.hpp\"\n\nint main()\n\n{\n\nprintHelloWorld();\n\nreturn 0;\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:52:02.467816Z","iopub.execute_input":"2025-02-16T08:52:02.468085Z","iopub.status.idle":"2025-02-16T08:52:02.480337Z","shell.execute_reply.started":"2025-02-16T08:52:02.468048Z","shell.execute_reply":"2025-02-16T08:52:02.479536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:08:47.806427Z","iopub.execute_input":"2025-02-11T05:08:47.806741Z","iopub.status.idle":"2025-02-11T05:08:47.925064Z","shell.execute_reply.started":"2025-02-11T05:08:47.806718Z","shell.execute_reply":"2025-02-11T05:08:47.924175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\ng++ cpphw.cpp -std=c++11 -o hw.out\n./hw.out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T05:08:56.090246Z","iopub.execute_input":"2025-02-11T05:08:56.090696Z","iopub.status.idle":"2025-02-11T05:08:56.389494Z","shell.execute_reply.started":"2025-02-11T05:08:56.090665Z","shell.execute_reply":"2025-02-11T05:08:56.388755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day 1 (16 Feb, 2025)","metadata":{}},{"cell_type":"code","source":"%%writefile vect_add_cpu.cpp\n// Sequential Vector Addition in CPP\n\n#include <iostream>\n#include <vector>\n#include <ctime>\nusing namespace std;\n\nint main(){\n    clock_t start = clock();\n    int n = 200000000;\n    vector<int> A(n), B(n), C(n);\n    for (int i=0; i<n; i++){\n        A[i] = i+1;\n        B[i] = (i+1)*2;\n    }\n\n    for (int i=0;i<n; i++){\n        C[i] = A[i] + B[i];\n\n    }\n\n    clock_t end = clock();\n\n    double duration = static_cast<double>(end - start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"Time taken: \" << duration * 1000 << \" milliseconds\" << std::endl; // Convert to milliseconds\n\n    for (int i=0;i <20; i++){\n        cout << C[i] << \" \";\n    }\n    return 0;\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T09:48:57.183546Z","iopub.execute_input":"2025-02-16T09:48:57.183884Z","iopub.status.idle":"2025-02-16T09:48:57.189127Z","shell.execute_reply.started":"2025-02-16T09:48:57.183856Z","shell.execute_reply":"2025-02-16T09:48:57.188139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\ng++ vect_add_cpu.cpp -std=c++11 -o cpu.out\n./cpu.out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T09:48:58.107757Z","iopub.execute_input":"2025-02-16T09:48:58.108042Z","iopub.status.idle":"2025-02-16T09:49:04.641248Z","shell.execute_reply.started":"2025-02-16T09:48:58.108021Z","shell.execute_reply":"2025-02-16T09:49:04.640176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile vect_add_gpu.cu\n// vector addition on gpu\n\n#include <iostream>\n#include <vector>\n#include <ctime>\n#include <cuda_runtime.h>\n\nusing namespace std;\n\n__global__ void vector_addition(int *A, int *B, int *C, int n){\n    // std::cout << \"blockIdx.x = \" << blockIdx.x << endl ;\n    // std::cout << \"blockDim.x = \" << blockDim.x << endl ;\n    // std::cout << \"threadIdx.x = \" << threadIdx.x << endl ;\n\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i<n){\n        C[i] = A[i] + B[i];\n    }\n    \n};\n\nint main(){\n    int n = 200000000;\n    vector<int> A(n), B(n), C(n);\n    for (int i=0; i<n; i++){\n        A[i] = i+1;\n        B[i] = (i+1)*2;\n    }\n\n    clock_t start = clock();\n    int *d_A, *d_B, *d_C;\n    cudaMalloc((void **)&d_A, n*sizeof(int));\n    cudaMalloc((void **)&d_B, n*sizeof(int));\n    cudaMalloc((void **)&d_C, n*sizeof(int));\n\n    cudaMemcpy(d_A, A.data(), n*sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B.data(), n*sizeof(int), cudaMemcpyHostToDevice);\n\n    int blockSize = 2;\n    int gridSize = n+blockSize - 1;\n    \n    vector_addition <<<gridSize, blockSize>>>(d_A, d_B, d_C, n);\n    cudaMemcpy(C.data(), d_C, n*sizeof(int), cudaMemcpyDeviceToHost);\n\n    clock_t end = clock();\n\n    double duration = static_cast<double>(end - start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"Time taken: \" << duration * 1000 << \" milliseconds\" << std::endl; // Convert to milliseconds\n\n    for (int i=0;i <20; i++){\n        cout << C[i] << \" \";\n    }\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n    \n    return 0;  \n}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T11:07:07.363220Z","iopub.execute_input":"2025-02-16T11:07:07.363529Z","iopub.status.idle":"2025-02-16T11:07:07.369766Z","shell.execute_reply.started":"2025-02-16T11:07:07.363507Z","shell.execute_reply":"2025-02-16T11:07:07.368812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%script bash\nnvcc vect_add_gpu.cu -o kernel\n./kernel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T11:07:11.333063Z","iopub.execute_input":"2025-02-16T11:07:11.333322Z","iopub.status.idle":"2025-02-16T11:07:19.223138Z","shell.execute_reply.started":"2025-02-16T11:07:11.333301Z","shell.execute_reply":"2025-02-16T11:07:19.222288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Notes:\n* Gird Dimension: gridDim.x, gridDim.y, gridDim.z is the number of blocks in each direction of Grid.\n* Block Dimension: blockDim.x, blockDim.y, blockDim.z, is the number of threads in each direction of block.\n* Block Index: blockIdx.x[y,z], index of the block within the grid\n* Thread Index: threadIdx.x[y,z], index of thread within a block\n  \nthreadId =\n\n            blockDim.x\\*blockIdx.x + blockDim.x\\*threadIdx.y + threadIdx.x (simple 2D within a block) +\n              \n            gridDim.x\\*blockDim.y\\*blockIdx.y (blocks of threads in previous row) \n\n\n**Steps:**\n1. Define the function to run on GPU.\n2. Declare variables on CPU and allocate necessary memory on GPU\n3. Copy the data from CPU to GPU on the allocated locations.\n4. Call the kernel\n5. Save the copy of the task result on the CPU.\n6. free the memory on GPU\n","metadata":{}},{"cell_type":"markdown","source":"# Day 2 (17 Feb, 2025)","metadata":{"execution":{"iopub.status.busy":"2025-02-17T17:26:03.433641Z","iopub.execute_input":"2025-02-17T17:26:03.434097Z","iopub.status.idle":"2025-02-17T17:26:03.439567Z","shell.execute_reply.started":"2025-02-17T17:26:03.434055Z","shell.execute_reply":"2025-02-17T17:26:03.437465Z"}}},{"cell_type":"code","source":"%%writefile vect_2D_add_gpu.cu\n// vector addition on gpu\n\n#include <iostream>\n#include <vector>\n#include <ctime>\n#include <cuda_runtime.h>\n\nusing namespace std;\n\n__global__ void vector_addition(int *A, int *B, int *C, int rows, int cols){\n    // std::cout << \"blockIdx.x = \" << blockIdx.x << endl ;\n    // std::cout << \"blockDim.x = \" << blockDim.x << endl ;\n    // std::cout << \"threadIdx.x = \" << threadIdx.x << endl ;\n\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row < rows && col < cols){\n        int index = row*cols + col;\n       // std::cout << index << endl;\n        C[index] = A[index] + B[index];\n    }\n    \n};\n\nvoid print_vector(vector<vector <int>> matrix){\n  // vector<vector<int>> matrix(3);\n    for (vector vec: matrix){\n      for (int val : vec){\n        cout << val << \" \";\n      }\n      cout << endl;\n    }\n}\n\n// Helper function to check for CUDA errors\nvoid checkCudaError(cudaError_t error) {\n    if (error != cudaSuccess) {\n        std::cerr << \"CUDA Error: \" << cudaGetErrorString(error) << std::endl;\n        exit(EXIT_FAILURE);\n    }\n}\n\nint main(){\n    \n    int rows = 30000;\n    int cols = 30000;\n    int n = rows*cols;\n    vector<int> h_A(n), h_B(n), h_C(n);\n    for (int i = 0; i < rows; ++i) {\n        for (int j = 0; j < cols; ++j) {\n            h_A[i * cols + j] = 2; // Example initialization for A\n            h_B[i * cols + j] = -1;\n                }\n    }\n\n    clock_t start_cpu = clock();\n    for (int i = 0; i < rows; ++i) {\n        for (int j = 0; j < cols; ++j) {\n            h_C[i * cols + j] = h_A[i * cols + j] + h_B[i * cols + j];\n                }\n    }\n    clock_t end_cpu = clock();\n    double duration_cpu = static_cast<double>(end_cpu - start_cpu) / CLOCKS_PER_SEC; // Time in seconds\n    std::cout << \"CPU Time taken: \" << duration_cpu * 1000 << \" milliseconds\" << std::endl; \n\n    clock_t start = clock();\n    int *d_A, *d_B, *d_C;\n    checkCudaError(cudaMalloc((void **)&d_A, n*sizeof(int)));\n    checkCudaError(cudaMalloc((void **)&d_B, n*sizeof(int)));\n    checkCudaError(cudaMalloc((void **)&d_C, n*sizeof(int)));\n\n    checkCudaError(cudaMemcpy(d_A, h_A.data(), n*sizeof(int), cudaMemcpyHostToDevice));\n    checkCudaError(cudaMemcpy(d_B, h_B.data(), n*sizeof(int), cudaMemcpyHostToDevice));\n\n    // dim3 blockSize(rows, cols); // Block dimension (threads per block in x and y) - adjust based on matrix size and GPU capabilities\n    // dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);\n\n    dim3 blockSize(16, 16); // Example block size\n    blockSize.x = min(blockSize.x, cols); // Clamp block size to cols\n    blockSize.y = min(blockSize.y, rows); // Clamp block size to rows\n    dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);\n    \n    vector_addition <<<gridSize, blockSize>>>(d_A, d_B, d_C, rows, cols);\n    checkCudaError(cudaGetLastError());\n    clock_t d2h_start = clock();\n    checkCudaError(cudaMemcpy(h_C.data(), d_C, n*sizeof(int), cudaMemcpyDeviceToHost));\n    clock_t d2h_end = clock();\n    double d2h_duration = static_cast<double>(d2h_end - d2h_start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"MemCpy D2H Time taken: \" << d2h_duration * 1000 << \" milliseconds\" << std::endl; \n\n    clock_t end = clock();\n\n    double duration_cuda = static_cast<double>(end - start) / CLOCKS_PER_SEC; // Time in seconds\n\n    std::cout << \"CUDA Time taken: \" << duration_cuda * 1000 << \" milliseconds\" << std::endl; \n    // Convert to milliseconds\n\n    cout << \"CUDA Matrix Addition (2D):\" << endl;\n    \n    for (int i = 0; i < 10; ++i) {\n        for (int j = 0; j < 10; ++j) {\n            cout << h_C[i * cols + j] << \" \";\n        }\n        cout << endl;\n    }\n    checkCudaError(cudaFree(d_A));\n    checkCudaError(cudaFree(d_B));\n    checkCudaError(cudaFree(d_C));\n    checkCudaError(cudaDeviceSynchronize());\n    \n    return 0;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T08:26:32.339234Z","iopub.execute_input":"2025-02-18T08:26:32.339539Z","iopub.status.idle":"2025-02-18T08:26:32.345121Z","shell.execute_reply.started":"2025-02-18T08:26:32.339512Z","shell.execute_reply":"2025-02-18T08:26:32.344349Z"}},"outputs":[{"name":"stdout","text":"Overwriting vect_2D_add_gpu.cu\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"%%script bash\nnvcc vect_2D_add_gpu.cu -o vect_2d\n./vect_2d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T08:26:38.174270Z","iopub.execute_input":"2025-02-18T08:26:38.174585Z","iopub.status.idle":"2025-02-18T08:27:11.215122Z","shell.execute_reply.started":"2025-02-18T08:26:38.174556Z","shell.execute_reply":"2025-02-18T08:27:11.214207Z"}},"outputs":[{"name":"stdout","text":"CPU Time taken: 6993.96 milliseconds\nMemCpy D2H Time taken: 806.245 milliseconds\nCUDA Time taken: 2479.75 milliseconds\nCUDA Matrix Addition (2D):\n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n1 1 1 1 1 1 1 1 1 1 \n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"Need to debug","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}